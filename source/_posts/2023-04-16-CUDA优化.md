---
title: 2023-04-16-CUDA优化
date: 2023-04-16 16:16
tags:
- cuda
categories:
- 学习
---

## SC07

[Microsoft PowerPoint - SC07_Optimization_Harris.ppt [Read-Only] (polytechnique.fr)](https://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf)

### 常见优化方法

优化目标
- 对于计算密集应用：峰值性能GFLOP/s
- 对于访存密集应用：峰值带宽bandwidth

### 二叉规约

是memory bound应用：
- 计算强度很低（1 flop/operator）

<!-- more -->

- 1: interleaved_addressing v1: 每个线程读取一个元素到SMEM，然后二叉规约（stride）
```c
__global__ void reduce0(int *g_idata, int *g_odata){
  extern __shared__ int sdata[];

  int tid = threadIdx.x;
  int i = blockIdx.x*blockDim.x + threadIdx.x;
  // each thread loads one element from global to shared mem
  sdata[tid] = g_idata[i];
  __syncthreads();

  //do reduction in SMEM
  for(int s=1; s<blockDim.x; s*=2){
    if(tid %(2*s)==0){
      sdata[tid] += sdata[tid + s];
    }
    __syncthreads();
  }

  //write result for this block to GMEM
  if(tid==0) g_odata[blockIdx.x] = sdata[0];
}
```
  - 线程分支diverge太多
如图，假设一个warp包含两个线程。则图中8个线程需要4个warp。而即使一个warp里只有一个线程，仍然需要占用一个warp。因此上面的算法会导致4+4+2+1=11次warp调用。
v2版本的代码则一个warp里的两个线程都是工作的，需要4+2+1+1=8次（盗图自：http://home.ustc.edu.cn/~shaojiemike/posts/nvidiaoptimize/）
![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/picgo/20230414195344.png)

- 2: interleaved_addressing v2:
```c
for(int s=1; s<blockDim.x; s*=2){
  int index = 2*s*tid;
  if(index < blockDim.x){
    sdata[index] += sdata[index+s];
  }
  __syncthreads();
}
```
  - SMEM bank conflict
- 3: sequential addressing
```c
for(int s=blockDim.x/2; s>0; s>>=1){
  if(tid < s){
    sdata[tid] += sdata[tid+s];
  }
  __syncthreads();
}
```
  - 第一次迭代就已经一半的线程是空闲的
- 4: first add during load：
  - 仍然达不到带宽上限，因此可能是指令开销
    - 辅助类指令(ancillary)：不是load, store和核心计算的算数指令
    - 即地址计算和循环开销
```c
<<<n/64/2, 64>>>kernel();

int i = blockIdx.x * (blockDim.x*2) + threadIdx.x;
sdata[tid] = g_idata[i] + g_idata[i + blockDim.x];
```
- 5：Unroll the last warp
  - 活动线程数随着规约迭代次数增加而减少
  - 当s<=32时，只有一个warp。warp内的指令时SIMD同步的。
    - 因此不需要__syncthread()，不需要if(tid < s)
```c
for(int s=blockDim.x/2; s>32; s>>=1){
  if(tid < s){
    sdata[tid] += sdata[tid+s];
  }
  __syncthreads();
}
if(tid<32){
  sdata[tid] = sdata[tid+32];
  sdata[tid] = sdata[tid+16];
  sdata[tid] = sdata[tid+8];
  sdata[tid] = sdata[tid+4];
  sdata[tid] = sdata[tid+2];
  sdata[tid] = sdata[tid+1];
}
```
- 6: completely Unrolled
  - 对于固定大小的线程块，可以完全展开。而GPU线程块的大小是2的幂，并且<1024。
  - 可以使用模板，针对不同的线程块完全展开
```c++
template<int blockSize>
__global__ void reduce5(int *g_idata, int *g_odata)
```

```c++
if(blockSize>=512){
  if(tid<256){sdata[tid]+=sdata[tid+256];} __syncthreads();
}
if(blockSize>=256){
  if(tid<128){sdata[tid]+=sdata[tid+128];} __syncthreads();
}
if(blockSize>=128){
  if(tid<64){sdata[tid]+=sdata[tid+64];} __syncthreads();
}
if(tid<32){
  if(blockSize >= 64) sdata[tid] = sdata[tid+32];
  if(blockSize >= 32) sdata[tid] = sdata[tid+16];
  if(blockSize >= 16) sdata[tid] = sdata[tid+8];
  if(blockSize >=  8) sdata[tid] = sdata[tid+4];
  if(blockSize >=  4) sdata[tid] = sdata[tid+2];
  if(blockSize >=  2) sdata[tid] = sdata[tid+1];
}
```

![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/picgo/20230414202641.png)

## GEMM

### 参考资料

[深入浅出GPU优化系列：GEMM优化（一） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/435908830)

### SC'2010 Fast implementation of DGEMM on Fermi GPU

为了让计算单元充分利用，不让访存称为瓶颈。根据实际硬件参数，可以得到对分块大小的一个下界
- $\#\mathrm{CUDA}\times\mathrm{freq}\times DW\times 1/2(1/b_m + 1/b_n)<BW$
  - DW表示元素字节数，如double float，8Byte
- 同理根据shard memory带宽，可以得到$r_x, r_y$的不等式

根据shared memory大小，可以得到分块大小的一个上界
$(b_m*b_k + b_n*b_k)*DW < M_{shared}$
根据register file的大小，得到rx, ry的上界
$(r_x+r_y+r_x*r_y)*{TRHEAD\_PER\_BLOCK} < 32768$

![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/picgo/20230404165730.png)


### 实践

- simple
  - C中每个元素每个对应一个线程。
    - 由于一个块内线程数有上限，因此仍然需要划分块。
- block shared memory
  - 可以发现计算C中相邻元素时，会利用重复的行或列。因此可以考虑将若干线程组织成一个块，共享一部分数据。刚好对应硬件的SMEM。

![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230419203646.png)
