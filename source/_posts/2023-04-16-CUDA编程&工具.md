---
title: 2023-04-16-CUDA编程&工具
date: 2023-04-16 16:13
tags:
- cuda
categories:
- 学习
---
## 参考资料

- [Tutorial 01: Say Hello to CUDA - CUDA Tutorial (cuda-tutorial.readthedocs.io)](https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/)
- [北京大学高性能计算平台 (pku.edu.cn)](https://hpc.pku.edu.cn/download_2_cuda.html)
  
## CUDA安装

总结：
- **最简单方式是看cuda下载页面提供的安装命令**
- deb安装貌似无法只安装cuda，不安装驱动
- runfile安装可以做到不重启
- cuda-toolkit-12-1包含cuda
- nvidia-driver-530包含驱动

<!-- more -->

### 有用链接

- 官方文档：[cuda-installation-guide-linux 12.1 documentation (nvidia.com)](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)

cuda下载
- 最新版：[CUDA Toolkit 12.1 Downloads | NVIDIA Developer](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04)
- 历史版：[CUDA Toolkit Archive | NVIDIA Developer](https://developer.nvidia.com/cuda-toolkit-archive)

### 依赖

*ps: 需要管理员权限*

- nvidia gpu & gpu driver
- gcc
- kernel header
```
sudo apt install linux-headers-$(uname -r)
```
> The CUDA Driver requires that the kernel headers and development packages for the running version of the kernel be installed at the time of the driver installation, as well whenever the driver is rebuilt.
- 禁用noveau驱动，安装cuda时也会自动安装nvidia驱动

### 两种方式

- rpm/deb packages
- runfile package
  - 和发行版无关(distribution-independent package)

安装deb后，是添加了一个repo。还需要再手动install cuda。
**不知为何安装cuda时一定会自动更新driver，而使用runfile方式，则可以选择不安装驱动。**

```
fyyuan@snode6 ➜  archive dpkg --list |grep cuda-repo
ii  cuda-repo-ubuntu2004-11-5-local                             11.5.2-495.29.05-1                                             amd64        cuda repository configuration files
ii  cuda-repo-ubuntu2004-12-1-local                             12.1.0-530.30.02-1                                             amd64        cuda repository configuration files
```

```
fyyuan@snode6 ➜  archive sudo apt install cuda --no-install-recommends
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following packages were automatically installed and are no longer required:
  cuda-11-5 cuda-cccl-11-5 cuda-command-line-tools-11-5 cuda-compiler-11-5 cuda-cudart-11-5 cuda-cudart-dev-11-5 cuda-cuobjdump-11-5 cuda-cupti-11-5 cuda-cupti-dev-11-5 cuda-cuxxfilt-11-5 cuda-demo-suite-11-5 cuda-documentation-11-5 cuda-driver-dev-11-5 cuda-gdb-11-5
  cuda-libraries-11-5 cuda-libraries-dev-11-5 cuda-memcheck-11-5 cuda-nsight-11-5 cuda-nsight-compute-11-5 cuda-nsight-systems-11-5 cuda-nvcc-11-5 cuda-nvdisasm-11-5 cuda-nvml-dev-11-5 cuda-nvprof-11-5 cuda-nvprune-11-5 cuda-nvrtc-11-5 cuda-nvrtc-dev-11-5 cuda-nvtx-11-5
  cuda-nvvp-11-5 cuda-runtime-11-5 cuda-samples-11-5 cuda-sanitizer-11-5 cuda-toolkit-11-5 cuda-toolkit-11-5-config-common cuda-toolkit-11-config-common cuda-tools-11-5 cuda-visual-tools-11-5 gds-tools-11-5 libcublas-11-5 libcublas-dev-11-5 libcufft-11-5 libcufft-dev-11-5
  libcufile-11-5 libcufile-dev-11-5 libcurand-11-5 libcurand-dev-11-5 libcusolver-11-5 libcusolver-dev-11-5 libcusparse-11-5 libcusparse-dev-11-5 libnpp-11-5 libnpp-dev-11-5 libnvidia-common-495 libnvjpeg-11-5 libnvjpeg-dev-11-5 nsight-compute-2021.3.1 nsight-systems-2021.3.3
Use 'sudo apt autoremove' to remove them.
The following additional packages will be installed:
  cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1 cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers
  cuda-drivers-530 cuda-gdb-12-1 cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1 cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1
  cuda-nvtx-12-1 cuda-nvvp-12-1 cuda-opencl-12-1 cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common cuda-toolkit-12-config-common cuda-tools-12-1 cuda-visual-tools-12-1 gds-tools-12-1 libcublas-12-1
  libcublas-dev-12-1 libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1 libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvidia-cfg1-530 libnvidia-common-530
  libnvidia-compute-530 libnvidia-decode-530 libnvidia-encode-530 libnvidia-extra-530 libnvidia-fbc1-530 libnvidia-gl-530 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1 libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.0 nsight-systems-2023.1.2
  nvidia-compute-utils-530 nvidia-dkms-530 nvidia-driver-530 nvidia-kernel-common-530 nvidia-kernel-source-530 nvidia-modprobe nvidia-settings nvidia-utils-530 xserver-xorg-video-nvidia-530
Recommended packages:
  libnvidia-compute-530:i386 libnvidia-decode-530:i386 libnvidia-encode-530:i386 libnvidia-fbc1-530:i386 libnvidia-gl-530:i386
The following packages will be REMOVED:
  cuda-drivers-495 libnvidia-cfg1-495 libnvidia-compute-495 libnvidia-decode-495 libnvidia-encode-495 libnvidia-extra-495 libnvidia-fbc1-495 libnvidia-gl-495 nvidia-compute-utils-495 nvidia-dkms-495 nvidia-driver-495 nvidia-kernel-common-495 nvidia-kernel-source-495
  nvidia-utils-495 xserver-xorg-video-nvidia-495
The following NEW packages will be installed:
  cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1 cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers-530
  cuda-gdb-12-1 cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1 cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1 cuda-nvtx-12-1 cuda-nvvp-12-1
  cuda-opencl-12-1 cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common cuda-toolkit-12-config-common cuda-tools-12-1 cuda-visual-tools-12-1 gds-tools-12-1 libcublas-12-1 libcublas-dev-12-1
  libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1 libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvidia-cfg1-530 libnvidia-common-530 libnvidia-compute-530
  libnvidia-decode-530 libnvidia-encode-530 libnvidia-extra-530 libnvidia-fbc1-530 libnvidia-gl-530 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1 libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.0 nsight-systems-2023.1.2 nvidia-compute-utils-530
  nvidia-dkms-530 nvidia-driver-530 nvidia-kernel-common-530 nvidia-kernel-source-530 nvidia-utils-530 xserver-xorg-video-nvidia-530
The following packages will be upgraded:
  cuda cuda-drivers nvidia-modprobe nvidia-settings
4 upgraded, 76 newly installed, 15 to remove and 21 not upgraded.
Need to get 0 B/3,012 MB of archives.
After this operation, 7,064 MB of additional disk space will be used.
Do you want to continue? [Y/n]
```

只安装cuda
```
fyyuan@snode6 ➜  archive sudo sh cuda_11.3.0_465.19.01_linux.run --toolkit
===========
= Summary =
===========

Driver:   Not Selected
Toolkit:  Installed in /usr/local/cuda-11.3/
Samples:  Installed in /usr/local/cuda-11.3/

Please make sure that
 -   PATH includes /usr/local/cuda-11.3/bin
 -   LD_LIBRARY_PATH includes /usr/local/cuda-11.3/lib64, or, add /usr/local/cuda-11.3/lib64 to /etc/ld.so.conf and run ldconfig as root

To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-11.3/bin
***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 465.00 is required for CUDA 11.3 functionality to work.
To install the driver using this installer, run the following command, replacing <CudaInstaller> with the name of this run file:
    sudo <CudaInstaller>.run --silent --driver

Logfile is /var/log/cuda-installer.log
```

### 不同版本冲突性

https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#handle-conflicting-installation-methods
总结：
- 安装cuda tookit，不同版本间没有冲突
- 安装driver，不同版本使用同一种方式(deb或runfile)安装没有冲突

### 卸载

```
sudo /usr/local/cuda-X.Y/bin/cuda-uninstaller  # runfile


# cuda
sudo apt-get --purge remove "*cuda*" "*cublas*" "*cufft*" "*cufile*" "*curand*" \
 "*cusolver*" "*cusparse*" "*gds-tools*" "*npp*" "*nvjpeg*" "nsight*" "*nvvm*"

# driver
sudo apt purge "*nvidia*" "libxnvctrl*"   # 只卸载nvidia-driver-xxx不够

sudo apt autoremove
```

### 环境变量选择版本

```
cuda_version="cuda-11.0"
export PATH="/usr/local/$cuda_version/bin:$PATH"
export LD_LIBRARY_PATH="/usr/local/$cuda_version/lib64:$LD_LIBRARY_PATH"
export demo_suite="/usr/local/$cuda_version/extras/demo_suite"

cd $demo_suite
./deviceQuery   # 获得设备信息
```

nvcc使用
```bash
nvcc -std=c++11 -lcurand -lcublas
```

### 实例

卸载runfile后重启（没重启还有很多nvdia的模块）
```
root@icarus3:/home/nfs/fyyuan# lsmod |grep nv
nvidia_drm             65536  0
nvidia_modeset       1273856  1 nvidia_drm
nvidia              55701504  27 gdrdrv,nvidia_modeset
drm_kms_helper        184320  4 ast,nvidia_drm
drm                   495616  7 drm_kms_helper,drm_vram_helper,ast,nvidia,nvidia_drm,ttm
```

安装driver
```
root@icarus3:/home/nfs/fyyuan# apt-cache policy nvidia-driver-530
nvidia-driver-530:
  Installed: 530.41.03-0ubuntu0.20.04.2
  Candidate: 530.41.03-0ubuntu0.20.04.2
  Version table:
 *** 530.41.03-0ubuntu0.20.04.2 500
        500 https://mirrors.ustc.edu.cn/ubuntu focal-updates/restricted amd64 Packages
        500 https://mirrors.ustc.edu.cn/ubuntu focal-security/restricted amd64 Packages
        100 /var/lib/dpkg/status
```

安装cuda
```
apt install nvidia-cuda-toolkit

root@icarus3:/home/nfs/fyyuan# nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
```

版本太老，为10.1的

i0上有许多apt source
- cuda-ubuntu2004-12-1-local.list对应/var/cuda-repo-ubuntu2004-12-1-local/，包含很多deb文件
- cuda-ubuntu2004-x86_64.list为https://developer.download.nvidia.com/compute/cuda
  `deb [signed-by=/usr/share/keyrings/cuda-archive-keyring.gpg] https://developer.download.nvidia.com/compute/cuda    /repos/ubuntu2004/x86_64/ /`
- source.list中还直接包含`deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /`
```
root@icarus0:/usr/local/cuda-12.1/bin# ls /etc/apt/sources.list.d/
cuda-ubuntu2004-12-1-local.list       docker.list       nvidia-container-toolkit.list.save
cuda-ubuntu2004-12-1-local.list.save  docker.list.save  nvidia-docker.list.save
cuda-ubuntu2004-x86_64.list           mlnx.list
cuda-ubuntu2004-x86_64.list.save      mlnx.list.save
```

官网按照deb(network)，发现添加了源，设置了
```
root@icarus3:/home/nfs/fyyuan# apt install cuda
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following additional packages will be installed:
  cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1
  cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers cuda-drivers-530 cuda-gdb-12-1
  cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1
  cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1 cuda-nvtx-12-1 cuda-nvvp-12-1 cuda-opencl-12-1
  cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common
  cuda-toolkit-12-config-common cuda-toolkit-config-common cuda-tools-12-1 cuda-visual-tools-12-1 default-jre default-jre-headless gds-tools-12-1
  libcublas-12-1 libcublas-dev-12-1 libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1
  libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1
  libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.1 nsight-systems-2023.1.2 nvidia-modprobe nvidia-settings openjdk-11-jre
  openjdk-11-jre-headless
Suggested packages:
  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic
The following NEW packages will be installed:
  cuda cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1
  cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers cuda-drivers-530 cuda-gdb-12-1
  cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1
  cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1 cuda-nvtx-12-1 cuda-nvvp-12-1 cuda-opencl-12-1
  cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common
  cuda-toolkit-12-config-common cuda-toolkit-config-common cuda-tools-12-1 cuda-visual-tools-12-1 default-jre default-jre-headless gds-tools-12-1
  libcublas-12-1 libcublas-dev-12-1 libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1
  libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1
  libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.1 nsight-systems-2023.1.2 nvidia-modprobe openjdk-11-jre openjdk-11-jre-headless
The following packages will be upgraded:
  nvidia-settings
1 upgraded, 69 newly installed, 0 to remove and 59 not upgraded.
Need to get 2802 MB of archives.
After this operation, 6511 MB of additional disk space will be used.
Do you want to continue? [Y/n]
```

## NVCC

On all platforms, the default host compiler executable (`gcc` and `g++` on Linux and `cl.exe` on Windows) found in the current execution search path will be used, unless specified otherwise with appropriate options

![](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/_images/cuda-compilation-from-cu-to-executable.png)

## Cuda编程

### 统一内存模型

在 CUDA 编程中，`__managed__` 是一个 CUDA 扩展关键字，用于标识被修饰的变量或数据结构将在主机（CPU）和设备（GPU）之间自动进行内存管理。它是 CUDA Unified Memory 功能的一部分，旨在简化主机和设备之间的内存管理和数据传输。

通过使用 `__managed__` 关键字，您可以将变量或数据结构声明为统一内存（Unified Memory）。这意味着在使用这些统一内存对象时，无需显式地在主机和设备之间进行手动内存分配和数据传输。CUDA 运行时系统会自动处理内存的分配和迁移，以确保数据在主机和设备之间正确共享。

### 同步

[cuda - Does __syncthreads() synchronize all threads in the grid? - Stack Overflow](https://stackoverflow.com/questions/15240432/does-syncthreads-synchronize-all-threads-in-the-grid)
```
__syncthreads()  // 该函数同步block内线程（实际是warp，warp内线程执行的是相同指令，本身就是同步的）
```

- cudaDeviceSynchronize
  - CPU等待GPU完成kernel调用

CUDA没有全局同步（block间同步）
- 对于SM数量很大的GPU，硬件成本太高
- would force programmer to run fewer blocks (no more than # multiprocessors * # resident blocks / multiprocessor) to avoid deadlock, which may reduce overall efficiency
解决办法：
分解为多个kernel
- kernel launch作为global sync point
- kernel launch has negligible HW overhead, low SW overhead

### cuBLAS

计算矩阵A x B
方式一：
```
cublasSgemm (blas_handle, CUBLAS_OP_T, CUBLAS_OP_T,   //CUBLAS使用列优先存储。CUBLAS_OP_T表示进行转置，即行优先。列优先下leading dimesion为m(mxn矩阵)
                     m, n, k,
                     &alpha,
                     d_A, k, d_B, n,
                     &beta,
                     d_C, n); //结果仍为列优先，故计算得到C的转置
```
方式二：
```
/* 通过计算B^T * A^T得到C^T，由于列优先所有d_C实际为C的行优先结果。 //https://stackoverflow.com/a/56064726
        疑问：这里beta等于0，故C的初始值没有影响，行列优先均可（ldc=m, n均正确）。但是如果非0，那么如何处理呢？
        */
        cublasSgemm(blas_handle, CUBLAS_OP_N, CUBLAS_OP_N,
                    n, m, k,
                    &alpha,
                    d_B, n, d_A, k,
                    &beta,
                    d_C, n);
```
# 工具

- IDE/debug/profile工具预览：[NVIDIA Developer Tools Overview | NVIDIA Developer](https://developer.nvidia.com/tools-overview)
## 总体介绍

- nvprof
- NVIDIA Visual Profiler

- cuda toolkit的一部分
- First introduced in 2008


nsight system


## nvprof

`Usage: nvprof [options] [application] [application-arguments]`

```
--analysis-metrics
                        Collect profiling data that can be imported to Visual Profiler's
                        "analysis" mode. Note: Use "--export-profile" to specify
                        an export file.

--devices <device ids>
                        Change the scope of subsequent "--events", "--metrics", "--query-events"
                        and "--query-metrics" options.
                        Allowed values:
                                all - change scope to all valid devices
                                comma-separated device IDs - change scope to specified
                        devices

  -e,  --events <event names>
                        Specify the events to be profiled on certain device(s). Multiple
                        event names separated by comma can be specified. Which device(s)
                        are profiled is controlled by the "--devices" option. Otherwise
                        events will be collected on all devices.
                        For a list of available events, use "--query-events".
                        Use "--events all" to profile all events available for each
                        device.
                        Use "--devices" and "--kernels" to select a specific kernel
                        invocation.
 --kernels <kernel path syntax>
                        Change the scope of subsequent "--events", "--metrics" options.
                        The syntax is as follows:
                                <kernel name>
                                Limit scope to given kernel name.
                        or
                                <context id/name>:<stream id/name>:<kernel name>:<invocation>
                        The context/stream IDs, names, kernel name and invocation
                        can be regular expressions. Empty string matches any number
                        or characters. If <context id/name> or <stream id/name>
                        is a positive number, it's strictly matched against the
                        CUDA context/stream ID. Otherwise it's treated as a regular
                        expression and matched against the context/stream name specified
                        by the NVTX library. If the invocation count is a positive
                        number, it's strictly matched against the invocation of
                        the kernel. Otherwise it's treated as a regular expression.
                        Example: --kernels "1:foo:bar:2" will profile any kernel
                        whose name contains "bar" and is the 2nd instance on context
                        1 and on stream named "foo".

  -m,  --metrics <metric names>
                        Specify the metrics to be profiled on certain device(s).
                        Multiple metric names separated by comma can be specified.
                        Which device(s) are profiled is controlled by the "--devices"
                        option. Otherwise metrics will be collected on all devices.
                        For a list of available metrics, use "--query-metrics".
                        Use "--metrics all" to profile all metrics available for
                        each device.
                        Use "--devices" and "--kernels" to select a specific kernel
                        invocation.
                        Note: "--metrics all" does not include some metrics which
                        are needed for Visual Profiler's source level analysis.
                        For that, use "--analysis-metrics".

 --pc-sampling-period <period>
                        Specify PC Sampling period in cycles,  at which the sampling
                        records will be dumped. Allowed values for the period are
                        integers between 5 to 31 both inclusive.
                        This will set the sampling period to (2^period) cycles
                        Default value is a number between 5 and 12 based on the setup.
                        Note: Only available for GM20X+.

 --print-api-summary
                  Print a summary of CUDA runtime/driver API calls.

 --print-api-trace
                  Print CUDA runtime/driver API trace.

 --print-gpu-trace
                        Print individual kernel invocations (including CUDA memcpy's/memset's)
                        and sort them in chronological order. In event/metric profiling
                        mode, show events/metrics for each kernel invocation.
  -s,  --print-summary
                        Print a summary of the profiling result on screen. Note:
                        This is the default unless "--export-profile" or other print
                        options are used.

  -o,  --export-profile <filename>
                        Export the result file which can be imported later or opened
                        by the NVIDIA Visual Profiler.
                                "%p" in the file name string is replaced with the
                        process ID of the application being profiled.
                                "%q{<ENV>}" in the file name string is replaced
                        with the value of the environment variable "<ENV>". If the
                        environment variable is not set it's an error.
                                "%h" in the file name string is replaced with the
                        hostname of the system.
                                "%%" in the file name string is replaced with "%".
                                Any other character following "%" is illegal.
                        By default, this option disables the summary output. Note:
                        If the application being profiled creates child processes,
                        or if '--profile-all-processes' is used, the "%p" format
                        is needed to get correct export files for each process.



```


metric具体含义：[1. Preparing An Application For Profiling — Profiler 12.3 documentation (nvidia.com)](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference)

>  The [Visual Profiler](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#visual-profiler) is a graphical profiling tool that displays a timeline of your application’s CPU and GPU activity, and that includes an automated analysis engine to identify optimization opportunities. The [nvprof](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof) profiling tool enables you to collect and view profiling data from the command-line.

下一代
> **Note that Visual Profiler and nvprof will be deprecated in a future CUDA release.** The NVIDIA Volta platform is the last architecture on which these tools are fully supported. It is recommended to use next-generation tools [NVIDIA Nsight Systems](https://developer.nvidia.com/nsight-systems) for GPU and CPU sampling and tracing and [NVIDIA Nsight Compute](https://developer.nvidia.com/nsight-compute) for GPU kernel profiling.

迁移：[1. Preparing An Application For Profiling — Profiler 12.3 documentation (nvidia.com)](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#migrating-to-nsight-tools-from-visual-profiler-and-nvprof)

- An **event** is a countable activity, action, or occurrence on a device. It corresponds to a single hardware counter value which is collected during kernel execution. To see a list of all available events on a particular NVIDIA GPU, type `nvprof --query-events`.
- A **metric** is a characteristic of an application that is calculated from one or more event values. To see a list of all available metrics on a particular NVIDIA GPU, type `nvprof --query-metrics`. You can also refer to the [metrics reference](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference) .

支持cudaProfilerStart, Stop CUDA API用于专注部分代码的分析。nvprof需要使用--profile-from-start off来使用

NVTX用于给CPU代码打上标记，好在工具里看到
> To understand what the application’s CPU threads are doing outside of CUDA function calls, you can use the [NVIDIA Tools Extension API](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvidia-tools-extension) (NVTX). When you add NVTX markers and ranges to your application, the [Timeline View](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#timeline-view) shows when your CPU threads are executing within those regions.


The Visual Profiler is available as both a standalone application and as part of Nsight Eclipse Edition. The standalone version of the Visual Profiler, `nvvp`, is included in the CUDA Toolkit for all supported OSes



流程
- 准备应用程序
  - 二进制程序，不用专门修改。但是使用NVTX更好

### NVVP

You must have one `nvprof` data file that contains the timeline information for the session. This data file should be collected by running nvprof with the `--export-profile` option. You can optionally enable other options such as `--system-profiling on`, but you should not collect any events or metrics as that will distort the timeline so that it is not representative of the applications true behavior.

You may optionally specify one or more event/metric data files that contain event and metric values for the application. These data files should be collected by running nvprof with one or both of the `--events` and `--metrics` options. To collect all the events and metrics that are needed for the analysis system, you can simply use the `--analysis-metrics` option along with the `--kernels` option to select the kernel(s) to collect events and metrics for. See [Remote Profiling](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#remote-profiling) for more information.

应用需要能够多次运行
> To collect performance data about your application, the Visual Profiler must be able to execute your application repeatedly in a deterministic manner.
## cuda SDK

- HPC SDK
[NVIDIA HPC SDK | NVIDIA NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc)
[Release Notes Version 23.3 (nvidia.com)](https://docs.nvidia.com/hpc-sdk/hpc-sdk-release-notes/index.html)

- HPC benchmark
[NVIDIA HPC-Benchmarks | NVIDIA NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/hpc-benchmarks)
## debug

### cuda-memck

使用cuda-memcheck检查程序是否有非法地址访问。会使得程序执行变慢
```
cuda-memcheck prog arg...
```

### cuda-gdb调试

```
nvcc -g -G XXX.cu -o XXX # -g对于cpu, -G对于GPU
```

cuda-gdb和gdb使用类似。

cuda程序如果代码写错，执行时只能从内核日志中看到报错信息（如Xid报错），非常不便。

而使用cuda-gdb可以直接定位哪出代码访存错误：
```
(cuda-gdb) r 10 10 10                                                                                                                                                                                                                                                                      Starting program: /staff/fyyuan/workspace/learn_cuda/gemm/GEMM 10 10 10                                                                                                                                                                                                                    [Thread debugging using libthread_db enabled]                                                                                                                                                                                                                                              Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".                                                                                                                                                                                                                                                                                                                                                                                                                                                             [Detaching after fork from child process 32599]                                                                                                                                                                                                                                            [New Thread 0x7fffdd982700 (LWP 32603)]                                                                                                                                                                                                                                                    [New Thread 0x7fffdd181700 (LWP 32604)]                                                                                                                                                                                                                                                    [New Thread 0x7fffdc87d700 (LWP 32605)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 CUDA Exception: Warp Illegal Address                                                                                                                                                                                                                                                       The exception was triggered at PC 0x55555617ff10 (GEMM.cu:82)

Thread 1 "GEMM" received signal CUDA_EXCEPTION_14, Warp Illegal Address.
[Switching focus to CUDA kernel 0, grid 4, block (0,0,0), thread (0,6,0), device 0, sm 0, warp 6, lane 0]
0x000055555617ff20 in gemm_block_shared<32, 32, 8><<<(32,32,1),(32,32,1)>>> (A=0x7fffbda00000, B=0x7fffd7800000, C=0x7fffd7c00000, m=1024,
    k=1024, n=1024) at GEMM.cu:82
82                  Bs[ty][tx] = B(iter * bm + ty, bx * bk + tx); //(tx, ty) in block B(iter, bx)
(cuda-gdb) quit
A debugging session is active.

        Inferior 1 [process 32589] will be killed.

Quit anyway? (y or n) y
```

## Nsight

- nvprof：sm7.5 之前使用，被nsight compute替代
- Nsight compute
  - 图形化界面
  - 命令行：ncu

### 问题

#### Profiling is not supported on this device
Nsight compute支持的GPU：[Release Notes :: Nsight Compute Documentation (nvidia.com)](https://docs.nvidia.com/nsight-compute/ReleaseNotes/index.html#gpu-support)
- 不支持pascal（如gtx1080），从Volta GV100开始支持

![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230419195327.png)


![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230419203147.png)


## NVbit


```cpp
unsigned int __ballot(int predicate); #
```
- If `predicate` is nonzero, `__ballot` returns a value with the `N`th bit set, where `N` is the thread index.

```csharp
int atomicOr(int* address, int val);
```

### warp-level指令

[CSE 599 I Accelerated Computing - Programming GPUs Lecture 18.pdf (tschmidt23.github.io)](https://tschmidt23.github.io/cse599i/CSE%20599%20I%20Accelerated%20Computing%20-%20Programming%20GPUs%20Lecture%2018.pdf)

![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230627162321.png)

![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230627162434.png)

![](https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230627163656.png)
